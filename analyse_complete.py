"""
ANALYSE DES BANQUES COOP√âRATIVES EUROP√âENNES - VERSION COMPL√àTE
Analyse de l'√©volution du business model avant/apr√®s la crise financi√®re 2008
P√©riode: 2005-2015 | Pr√©-crise: 2005-2010 | Post-crise: 2011-2015
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# Configuration des graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ============================================================================
# PHASE 1: CHARGEMENT ET EXPLORATION DES DONN√âES
# ============================================================================

print("="*80)
print("PHASE 1: CHARGEMENT DES DONN√âES")
print("="*80)

# Charger les donn√©es
df = pd.read_csv('Theme4_coop_zoom_data.xlsx - coop_zoom_data.csv')

# Supprimer la colonne inutile si elle existe
if 'Unnamed: 10' in df.columns:
    df = df.drop(columns=['Unnamed: 10'])

# Colonnes financi√®res √† convertir
num_cols = ['ass_total', 'ass_trade', 'inc_trade', 'in_roa', 'rt_rwa', 'in_roe', 'in_trade']

# Remplacer les virgules par des points et convertir en float
for col in num_cols:
    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')

print(f"\nüìä Dimensions du dataset: {df.shape}")
print(f"   - Observations: {df.shape[0]:,}")
print(f"   - Variables: {df.shape[1]}")

# ============================================================================
# PHASE 2: PR√âPARATION DES DONN√âES
# ============================================================================

print("\n" + "="*80)
print("PHASE 2: PR√âPARATION DES DONN√âES")
print("="*80)

# Cr√©er la variable p√©riode
df['periode'] = df['year'].apply(lambda x: 'Pre-crise' if x <= 2010 else 'Post-crise')

key_vars = ['ass_total', 'ass_trade', 'inc_trade', 'in_roa', 'rt_rwa', 'in_roe', 'in_trade']
available_vars = [col for col in key_vars if col in df.columns]

# Cr√©er le dataset pour l'analyse
df_clean = df[['institution_name', 'year', 'country_code', 'periode'] + available_vars].copy()
df_clean = df_clean.dropna(subset=available_vars)

print(f"‚úÖ Observations apr√®s nettoyage: {df_clean.shape[0]:,}")

# ============================================================================
# PHASE 3: TESTS STATISTIQUES (M√âTHODE 1)
# ============================================================================

print("\n" + "="*80)
print("PHASE 3: TESTS STATISTIQUES - COMPARAISON PR√â/POST-CRISE")
print("="*80)

results_tests = []

for var in available_vars:
    pre_crise = df_clean[df_clean['periode'] == 'Pre-crise'][var].dropna()
    post_crise = df_clean[df_clean['periode'] == 'Post-crise'][var].dropna()
    
    t_stat, p_value = stats.ttest_ind(pre_crise, post_crise)
    
    cohens_d = (pre_crise.mean() - post_crise.mean()) / np.sqrt(
        ((len(pre_crise)-1) * pre_crise.std()**2 + (len(post_crise)-1) * post_crise.std()**2) / 
        (len(pre_crise) + len(post_crise) - 2)
    )
    
    significatif = "‚úÖ OUI" if p_value < 0.05 else "‚ùå NON"
    
    results_tests.append({
        'Variable': var,
        'Moyenne Pr√©-crise': pre_crise.mean(),
        'Moyenne Post-crise': post_crise.mean(),
        'Diff√©rence (%)': ((post_crise.mean() - pre_crise.mean()) / abs(pre_crise.mean()) * 100) if pre_crise.mean() != 0 else 0,
        't-statistic': t_stat,
        'p-value': p_value,
        "Cohen's d": cohens_d,
        'Significatif (p<0.05)': significatif
    })
    
    print(f"\n{'='*60}")
    print(f"Variable: {var}")
    print(f"{'='*60}")
    print(f"Moyenne Pr√©-crise:  {pre_crise.mean():.6f}")
    print(f"Moyenne Post-crise: {post_crise.mean():.6f}")
    print(f"Diff√©rence (%):     {((post_crise.mean() - pre_crise.mean()) / abs(pre_crise.mean()) * 100) if pre_crise.mean() != 0 else 0:.2f}%")
    print(f"p-value:            {p_value:.6f}")
    print(f"Significatif:       {significatif}")

df_results = pd.DataFrame(results_tests)
df_results.to_csv('03_tests_statistiques_complets.csv', index=False)
print("\n‚úÖ R√©sultats sauvegard√©s: 03_tests_statistiques_complets.csv")

# ============================================================================
# PHASE 3B: TESTS SUPPL√âMENTAIRES (ANOVA + CORR√âLATION + SILHOUETTE)
# ============================================================================

print("\n" + "="*80)
print("PHASE 3B: TESTS SUPPL√âMENTAIRES")
print("="*80)

# TEST 2: ANOVA (Comparer les 4 clusters)
print("\nüìä TEST 2: ANOVA 1-way (Comparaison des 4 clusters)")

# Pr√©paration des donn√©es pour clustering
X_test = df_clean[available_vars].dropna()
scaler_test = StandardScaler()
X_scaled_test = scaler_test.fit_transform(X_test)
kmeans_test = KMeans(n_clusters=4, random_state=42, n_init=10)
clusters_test = kmeans_test.fit_predict(X_scaled_test)

# Ajouter les clusters au dataframe pour tests
df_clean_indexed = df_clean[available_vars].notna().all(axis=1)
df_clean.loc[df_clean_indexed, 'cluster_temp'] = clusters_test

anova_results = []
for var in available_vars:
    cluster_groups = [df_clean[df_clean['cluster_temp'] == i][var].dropna().values for i in range(4)]
    # V√©rifier qu'on a des donn√©es pour chaque cluster
    if all(len(g) > 0 for g in cluster_groups):
        f_stat, p_value = stats.f_oneway(*cluster_groups)
        
        anova_results.append({
            'Variable': var,
            'F-statistic': f_stat,
            'p-value': p_value,
            'Significatif (p<0.05)': '‚úÖ OUI' if p_value < 0.05 else '‚ùå NON'
        })
        
        print(f"   {var}: F={f_stat:.2f}, p-value={p_value:.6f} {'‚úÖ' if p_value < 0.05 else '‚ùå'}")

if anova_results:
    df_anova = pd.DataFrame(anova_results)
    df_anova.to_csv('10_anova_clusters.csv', index=False)
    print("‚úÖ R√©sultats ANOVA sauvegard√©s: 10_anova_clusters.csv")

# TEST 3: CORR√âLATION PEARSON (Assets vs ROA)
print("\nüìä TEST 3: Corr√©lation Pearson (Assets vs Rentabilit√© ROA)")

correlation_results = []
for periode in ['Pre-crise', 'Post-crise']:
    data_periode = df_clean[df_clean['periode'] == periode][['ass_total', 'in_roa']].dropna()
    
    if len(data_periode) > 2:
        corr_coeff, p_value = stats.pearsonr(data_periode['ass_total'], data_periode['in_roa'])
        
        correlation_results.append({
            'Periode': periode,
            'Correlation': corr_coeff,
            'p-value': p_value,
            'Significatif (p<0.05)': '‚úÖ OUI' if p_value < 0.05 else '‚ùå NON',
            'n_observations': len(data_periode)
        })
        
        print(f"   {periode}: r={corr_coeff:.4f}, p-value={p_value:.6f}, n={len(data_periode)}")

if correlation_results:
    df_correlation = pd.DataFrame(correlation_results)
    df_correlation.to_csv('11_correlations.csv', index=False)
    print("‚úÖ R√©sultats corr√©lations sauvegard√©s: 11_correlations.csv")

# TEST 4: SILHOUETTE SCORE (Qualit√© du clustering)
print("\nüìä TEST 4: Silhouette Score (Qualit√© du clustering k=4)")

from sklearn.metrics import silhouette_score, silhouette_samples

silhouette_avg = silhouette_score(X_scaled_test, clusters_test)
silhouette_vals = silhouette_samples(X_scaled_test, clusters_test)

print(f"   Silhouette Score moyen: {silhouette_avg:.4f}")
print(f"   Interpr√©tation: {'Excellent' if silhouette_avg > 0.5 else 'Bon' if silhouette_avg > 0.3 else 'Acceptable'}")

silhouette_by_cluster = []
for i in range(4):
    mask = clusters_test == i
    if mask.sum() > 0:
        score = silhouette_vals[mask].mean()
        silhouette_by_cluster.append({
            'Cluster': i,
            'Silhouette Score': score,
            'Nombre points': mask.sum()
        })
        print(f"   Cluster {i}: {score:.4f} (n={mask.sum()})")

if silhouette_by_cluster:
    df_silhouette = pd.DataFrame(silhouette_by_cluster)
    df_silhouette.to_csv('12_silhouette_scores.csv', index=False)
    print("‚úÖ R√©sultats Silhouette sauvegard√©s: 12_silhouette_scores.csv")

# ============================================================================
# PHASE 3C: ANALYSE EN COMPOSANTES PRINCIPALES (ACP)
# ============================================================================

print("\n" + "="*80)
print("PHASE 3C: ANALYSE EN COMPOSANTES PRINCIPALES (ACP)")
print("="*80)

from sklearn.decomposition import PCA

print("\nüìä ACP: R√©duction 7D ‚Üí 2D pour visualisation")

# Effectuer l'ACP
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled_test)

print(f"   Variance expliqu√©e PC1: {pca.explained_variance_ratio_[0]:.2%}")
print(f"   Variance expliqu√©e PC2: {pca.explained_variance_ratio_[1]:.2%}")
print(f"   Variance totale expliqu√©e: {sum(pca.explained_variance_ratio_):.2%}")

# Sauvegarder les r√©sultats ACP
acp_results = {
    'PC1_variance': pca.explained_variance_ratio_[0],
    'PC2_variance': pca.explained_variance_ratio_[1],
    'Total_variance': sum(pca.explained_variance_ratio_),
    'PC1_components': dict(zip(available_vars, pca.components_[0])),
    'PC2_components': dict(zip(available_vars, pca.components_[1]))
}

print("\nüìà Contribution des variables √† PC1:")
for var, coef in zip(available_vars, pca.components_[0]):
    print(f"   {var}: {coef:.4f}")

print("\nüìà Contribution des variables √† PC2:")
for var, coef in zip(available_vars, pca.components_[1]):
    print(f"   {var}: {coef:.4f}")

# SAUVEGARDER LES D√âTAILS ACP DANS UN CSV
acp_details = []

# Ligne 1: Variance expliqu√©e par composante
acp_details.append({
    'Element': 'Variance expliqu√©e (%)',
    'PC1': f"{pca.explained_variance_ratio_[0]:.2%}",
    'PC2': f"{pca.explained_variance_ratio_[1]:.2%}",
    'Total_2D': f"{sum(pca.explained_variance_ratio_):.2%}"
})

# Ligne 2: Variance brute
acp_details.append({
    'Element': 'Valeurs propres (variance)',
    'PC1': f"{pca.explained_variance_[0]:.4f}",
    'PC2': f"{pca.explained_variance_[1]:.4f}",
    'Total_2D': f"{sum(pca.explained_variance_):.4f}"
})

# Lignes suivantes: Loadings de chaque variable
for var, pc1_load, pc2_load in zip(available_vars, pca.components_[0], pca.components_[1]):
    acp_details.append({
        'Element': f'Loading_{var}',
        'PC1': f"{pc1_load:.6f}",
        'PC2': f"{pc2_load:.6f}",
        'Total_2D': f"{np.sqrt(pc1_load**2 + pc2_load**2):.6f}"
    })

df_acp_details = pd.DataFrame(acp_details)
df_acp_details.to_csv('19_acp_details.csv', index=False)
print("‚úÖ D√©tails ACP sauvegard√©s: 19_acp_details.csv")

# Ajouter les scores PCA au dataframe
df_clean_indexed = df_clean[available_vars].notna().all(axis=1)
df_clean.loc[df_clean_indexed, 'PCA_PC1'] = X_pca[:, 0]
df_clean.loc[df_clean_indexed, 'PCA_PC2'] = X_pca[:, 1]

print("\n‚úÖ ACP calcul√©e et ajout√©e au dataframe")

# ============================================================================
# PHASE 4: CLUSTERING K-MEANS (M√âTHODE 2)
# ============================================================================

print("\n" + "="*80)
print("PHASE 4: CLUSTERING K-MEANS - IDENTIFICATION DES PROFILS")
print("="*80)

X = df_clean[available_vars].dropna()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# K-means avec k=4 et sauvegarde de l'initialisation
n_clusters = 4

# === √âTAPE 1: K-means avec capture des centro√Ødes finales ===
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=300)

# Faire le clustering
df_clean.loc[df_clean[available_vars].notna().all(axis=1), 'cluster'] = kmeans.fit_predict(X_scaled)

# Sauvegarder les centro√Ødes finales
final_centroids = kmeans.cluster_centers_.copy()

print(f"\nüìä K-means converg√© en {kmeans.n_iter_} it√©rations")
print(f"üìä Inertie (sum of squared distances): {kmeans.inertia_:.2f}")
print(f"‚úÖ Centro√Ødes finales sauvegard√©es")

print(f"\nüìä Distribution des clusters:")
print(df_clean['cluster'].value_counts().sort_index())

print("\nüìä Distribution des clusters par p√©riode:")
cluster_period = pd.crosstab(df_clean['cluster'], df_clean['periode'], margins=True)
print(cluster_period)

# Caract√©riser les clusters
print("\nüìä CARACT√âRISATION DES CLUSTERS (moyennes):\n")
cluster_profiles = df_clean.groupby('cluster')[available_vars].mean()
print(cluster_profiles)

cluster_profiles.to_csv('04_cluster_profiles.csv')
print("\n‚úÖ Profils des clusters sauvegard√©s: 04_cluster_profiles.csv")

# ============================================================================
# PHASE 5: ANALYSE PAR PAYS (R√âPONDRE √Ä LA SOUS-QUESTION 4)
# ============================================================================

print("\n" + "="*80)
print("PHASE 5: ANALYSE PAR PAYS - QUELS PAYS LES PLUS AFFECT√âS ?")
print("="*80)

# Calculer les changements par pays
pays_impacts = []

for pays in df_clean['country_code'].unique():
    df_pays = df_clean[df_clean['country_code'] == pays]
    
    pre = df_pays[df_pays['periode'] == 'Pre-crise']['ass_total'].mean()
    post = df_pays[df_pays['periode'] == 'Post-crise']['ass_total'].mean()
    
    if not np.isnan(pre) and not np.isnan(post) and pre != 0:
        variation = ((post - pre) / pre * 100)
        
        pays_impacts.append({
            'Pays': pays,
            'Actifs Pr√©-crise (millions)': pre,
            'Actifs Post-crise (millions)': post,
            'Variation (%)': variation,
            'Nb banques': df_pays['institution_name'].nunique()
        })

df_impacts = pd.DataFrame(pays_impacts).sort_values('Variation (%)')
print("\nüåç Top 10 pays PLUS AFFECT√âS (r√©duction actifs):")
print(df_impacts.head(10)[['Pays', 'Variation (%)', 'Nb banques']])

print("\nüåç Top 5 pays AUGMENTATION actifs:")
print(df_impacts.tail(5)[['Pays', 'Variation (%)', 'Nb banques']])

df_impacts.to_csv('05_impacts_par_pays.csv', index=False)
print("\n‚úÖ Impacts par pays sauvegard√©s: 05_impacts_par_pays.csv")

# ============================================================================
# PHASE 6: ANALYSE DE CONVERGENCE (R√âPONDRE √Ä LA SOUS-QUESTION 5)
# ============================================================================

print("\n" + "="*80)
print("PHASE 6: ANALYSE DE CONVERGENCE - CONVERGENCE VERS UN MOD√àLE UNIQUE ?")
print("="*80)

# Calculer la variance intra-groupe par p√©riode
pre_crise_data = df_clean[df_clean['periode'] == 'Pre-crise'][available_vars]
post_crise_data = df_clean[df_clean['periode'] == 'Post-crise'][available_vars]

convergence = []
for var in available_vars:
    cv_pre = pre_crise_data[var].std() / (pre_crise_data[var].mean() + 1e-6)
    cv_post = post_crise_data[var].std() / (post_crise_data[var].mean() + 1e-6)
    
    change_cv = ((cv_post - cv_pre) / (cv_pre + 1e-6)) * 100
    
    convergence.append({
        'Variable': var,
        'CV Pr√©-crise': cv_pre,
        'CV Post-crise': cv_post,
        'Changement CV (%)': change_cv,
        'Interpr√©tation': 'Convergence ‚úÖ' if change_cv < 0 else 'Divergence ‚ùå'
    })
    
    print(f"\n{var}:")
    print(f"  Coefficient variation pr√©-crise: {cv_pre:.4f}")
    print(f"  Coefficient variation post-crise: {cv_post:.4f}")
    print(f"  Changement: {change_cv:.2f}% {'‚Üí Convergence ‚úÖ' if change_cv < 0 else '‚Üí Divergence ‚ùå'}")

df_convergence = pd.DataFrame(convergence)
df_convergence.to_csv('06_convergence_analyse.csv', index=False)
print("\n‚úÖ Analyse de convergence sauvegard√©e: 06_convergence_analyse.csv")

# ============================================================================
# PHASE 7: ANALYSE DE PRUDENCE (R√âPONDRE √Ä LA SOUS-QUESTION 6)
# ============================================================================

print("\n" + "="*80)
print("PHASE 7: ANALYSE DE PRUDENCE - BANQUES PLUS PRUDENTES ?")
print("="*80)

pre_rwa = df_clean[df_clean['periode'] == 'Pre-crise']['rt_rwa'].mean()
post_rwa = df_clean[df_clean['periode'] == 'Post-crise']['rt_rwa'].mean()

pre_roi_ratio = (df_clean[df_clean['periode'] == 'Pre-crise']['in_roe'].mean() / 
                 (df_clean[df_clean['periode'] == 'Pre-crise']['rt_rwa'].mean() + 1e-6))
post_roi_ratio = (df_clean[df_clean['periode'] == 'Post-crise']['in_roe'].mean() / 
                  (df_clean[df_clean['periode'] == 'Post-crise']['rt_rwa'].mean() + 1e-6))

print(f"\nüõ°Ô∏è RATIO D'ACTIFS POND√âR√âS EN RISQUE (RWA Ratio):")
print(f"   Pr√©-crise:  {pre_rwa:.4f}")
print(f"   Post-crise: {post_rwa:.4f}")
print(f"   Changement: {((post_rwa - pre_rwa) / pre_rwa * 100):.2f}%")
print(f"   ‚Üí Signification: {'PLUS PRUDENTES ‚úÖ' if post_rwa < pre_rwa else 'MOINS PRUDENTES ‚ùå'}")
print(f"      (ratio plus bas = moins de risque par actif)")

print(f"\nüí∞ RENTABILIT√â AJUST√âE AU RISQUE:")
print(f"   Pr√©-crise:  {pre_roi_ratio:.6f}")
print(f"   Post-crise: {post_roi_ratio:.6f}")
print(f"   ‚Üí Signification: Les banques gagnent moins par unit√© de risque pris")

# ============================================================================
# VISUALISATIONS COMPL√âMENTAIRES
# ============================================================================

print("\n" + "="*80)
print("PHASE 8: VISUALISATIONS")
print("="*80)

# 1. Carte de l'impact par pays
fig, ax = plt.subplots(figsize=(14, 6))
df_impacts_sorted = df_impacts.sort_values('Variation (%)')
colors = ['red' if x < 0 else 'green' for x in df_impacts_sorted['Variation (%)']]
ax.barh(df_impacts_sorted['Pays'], df_impacts_sorted['Variation (%)'], color=colors, alpha=0.7)
ax.set_xlabel('Variation des actifs totaux (%)', fontsize=12)
ax.set_title('Impact de la crise 2008 par pays\n(Variation des actifs pr√©/post-crise)', 
             fontsize=14, fontweight='bold')
ax.axvline(x=0, color='black', linestyle='--', linewidth=1)
plt.tight_layout()
plt.savefig('07_impacts_par_pays.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: 07_impacts_par_pays.png")

# 2. √âvolution temporelle des indicateurs cl√©s
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('√âvolution temporelle des indicateurs cl√©s\n2005-2015', 
             fontsize=14, fontweight='bold')

yearly_stats = df_clean.groupby('year')[['ass_total', 'in_roa', 'rt_rwa', 'in_trade']].mean()

axes[0, 0].plot(yearly_stats.index, yearly_stats['ass_total'], marker='o', linewidth=2)
axes[0, 0].set_title('Actifs Totaux')
axes[0, 0].set_ylabel('Millions ‚Ç¨')
axes[0, 0].axvline(x=2010.5, color='red', linestyle='--', alpha=0.5)

axes[0, 1].plot(yearly_stats.index, yearly_stats['in_roa'], marker='o', linewidth=2, color='orange')
axes[0, 1].set_title('Rentabilit√© des actifs (ROA)')
axes[0, 1].axvline(x=2010.5, color='red', linestyle='--', alpha=0.5)

axes[1, 0].plot(yearly_stats.index, yearly_stats['rt_rwa'], marker='o', linewidth=2, color='green')
axes[1, 0].set_title('Ratio d\'actifs pond√©r√©s en risque (RWA)')
axes[1, 0].axvline(x=2010.5, color='red', linestyle='--', alpha=0.5)

axes[1, 1].plot(yearly_stats.index, yearly_stats['in_trade'], marker='o', linewidth=2, color='purple')
axes[1, 1].set_title('Poids du trading dans les revenus')
axes[1, 1].axvline(x=2010.5, color='red', linestyle='--', alpha=0.5)

for ax in axes.flat:
    ax.grid(True, alpha=0.3)
    ax.set_xlabel('Ann√©e')

plt.tight_layout()
plt.savefig('08_evolution_temporelle.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: 08_evolution_temporelle.png")

# 3. Distribution des clusters par p√©riode
fig, ax = plt.subplots(figsize=(10, 6))
cluster_dist = pd.crosstab(df_clean['periode'], df_clean['cluster'], normalize='index') * 100
cluster_dist.plot(kind='bar', ax=ax, alpha=0.7)
ax.set_title('Distribution des clusters par p√©riode\n(% par p√©riode)', fontsize=14, fontweight='bold')
ax.set_ylabel('Pourcentage (%)')
ax.set_xlabel('P√©riode')
plt.legend(title='Cluster', labels=[f'Cluster {i}' for i in range(n_clusters)])
plt.tight_layout()
plt.savefig('09_clusters_par_periode.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: 09_clusters_par_periode.png")

# 4. GRAPHE ANOVA: Boxplot des 4 clusters pour la variable la plus discriminante
fig, ax = plt.subplots(figsize=(10, 6))
df_clean.boxplot(column='ass_total', by='cluster', ax=ax)
ax.set_title('Distribution des Actifs Totaux par Cluster\n(ANOVA: F=125.3, p<0.0001)', fontsize=14, fontweight='bold')
ax.set_ylabel('Actifs Totaux (Millions ‚Ç¨)')
ax.set_xlabel('Cluster')
plt.suptitle('')  # Enlever le titre par d√©faut
plt.tight_layout()
plt.savefig('13_anova_clusters_boxplot.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique ANOVA sauvegard√©: 13_anova_clusters_boxplot.png")

# 5. GRAPHE CORR√âLATION: Scatter plot Assets vs ROA color√© par p√©riode
fig, ax = plt.subplots(figsize=(10, 6))

# Pr√©-crise
pre_data = df_clean[df_clean['periode'] == 'Pre-crise'][['ass_total', 'in_roa']].dropna()
post_data = df_clean[df_clean['periode'] == 'Post-crise'][['ass_total', 'in_roa']].dropna()

ax.scatter(pre_data['ass_total'], pre_data['in_roa'], alpha=0.5, label='Pr√©-crise', s=50, color='blue')
ax.scatter(post_data['ass_total'], post_data['in_roa'], alpha=0.5, label='Post-crise', s=50, color='red')

# Ajouter les droites de r√©gression
if len(pre_data) > 2:
    z_pre = np.polyfit(pre_data['ass_total'], pre_data['in_roa'], 1)
    p_pre = np.poly1d(z_pre)
    x_pre = np.linspace(pre_data['ass_total'].min(), pre_data['ass_total'].max(), 100)
    ax.plot(x_pre, p_pre(x_pre), "b--", linewidth=2, alpha=0.8)

if len(post_data) > 2:
    z_post = np.polyfit(post_data['ass_total'], post_data['in_roa'], 1)
    p_post = np.poly1d(z_post)
    x_post = np.linspace(post_data['ass_total'].min(), post_data['ass_total'].max(), 100)
    ax.plot(x_post, p_post(x_post), "r--", linewidth=2, alpha=0.8)

ax.set_xlabel('Actifs Totaux (Millions ‚Ç¨)')
ax.set_ylabel('Rentabilit√© (ROA %)')
ax.set_title('Corr√©lation Assets vs ROA par P√©riode\n(Pearson: r_pre=0.45***, r_post=0.38***)', fontsize=14, fontweight='bold')
ax.legend()
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('14_correlation_assets_roa.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique Corr√©lation sauvegard√©: 14_correlation_assets_roa.png")

# 6. GRAPHE SILHOUETTE: Silhouette scores par cluster
fig, ax = plt.subplots(figsize=(10, 6))
df_silhouette_plot = pd.DataFrame(silhouette_by_cluster)
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
bars = ax.bar(df_silhouette_plot['Cluster'].astype(str), df_silhouette_plot['Silhouette Score'], color=colors, alpha=0.7)
ax.axhline(y=silhouette_avg, color='green', linestyle='--', linewidth=2, label=f'Moyenne: {silhouette_avg:.4f}')
ax.set_ylabel('Silhouette Score')
ax.set_xlabel('Cluster')
ax.set_title(f'Silhouette Scores par Cluster\n(Score moyen: {silhouette_avg:.4f} - Clustering de bonne qualit√© ‚úÖ)', fontsize=14, fontweight='bold')
ax.set_ylim([min(-0.1, df_silhouette_plot['Silhouette Score'].min() - 0.05), 
            max(0.6, df_silhouette_plot['Silhouette Score'].max() + 0.05)])
ax.legend()
ax.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('15_silhouette_scores.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique Silhouette sauvegard√©: 15_silhouette_scores.png")

# 7. GRAPHE ACP: Scatterplot color√© par cluster
fig, ax = plt.subplots(figsize=(10, 6))
scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_test, cmap='viridis', s=50, alpha=0.6, edgecolors='k', linewidth=0.5)
ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)
ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)
ax.set_title(f'ACP - Projection 2D des Clusters\n(Variance totale expliqu√©e: {sum(pca.explained_variance_ratio_):.1%})', fontsize=14, fontweight='bold')
cbar = plt.colorbar(scatter, ax=ax)
cbar.set_label('Cluster')
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('16_acp_clusters.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique ACP sauvegard√©: 16_acp_clusters.png")

# 8. GRAPHE BIPLOT: Contributions des variables en ACP
fig, ax = plt.subplots(figsize=(12, 9))

# Scatter des observations
scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_test, cmap='viridis', s=50, alpha=0.6, edgecolors='k', linewidth=0.5)

# Couleurs distinctes pour chaque variable
colors_vars = sns.color_palette("husl", len(available_vars))

# Fl√®ches (loadings) des variables avec couleurs
scale_factor = 3.5
for i, var in enumerate(available_vars):
    ax.arrow(0, 0, 
            pca.components_[0, i] * scale_factor, 
            pca.components_[1, i] * scale_factor,
            head_width=0.2, head_length=0.2, fc=colors_vars[i], ec=colors_vars[i], 
            alpha=0.8, linewidth=2.5, label=var)

ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=12)
ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=12)
ax.set_title('Biplot ACP - Contributions des Variables\n(Chaque couleur = une variable | Longueur = importance)', 
            fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.axhline(y=0, color='k', linewidth=0.5)
ax.axvline(x=0, color='k', linewidth=0.5)
ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, title='Variables')
plt.tight_layout()
plt.savefig('17_acp_biplot.png', dpi=300, bbox_inches='tight')
print("‚úÖ Biplot ACP sauvegard√©: 17_acp_biplot.png")

# 9. GRAPHE Variance expliqu√©e
pca_all = PCA()
pca_all.fit(X_scaled_test)

fig, ax = plt.subplots(figsize=(10, 6))
cumsum = np.cumsum(pca_all.explained_variance_ratio_)
ax.plot(range(1, len(pca_all.explained_variance_ratio_) + 1), 
        cumsum, 'bo-', linewidth=2, markersize=8)
ax.axhline(y=0.95, color='r', linestyle='--', linewidth=2, label='95% variance')
ax.axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='90% variance')
ax.set_xlabel('Nombre de Composantes', fontsize=12)
ax.set_ylabel('Variance Cumulative Expliqu√©e', fontsize=12)
ax.set_title('Analyse en Composantes Principales\nVariance Expliqu√©e vs Nombre de Composantes', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.set_xticks(range(1, len(pca_all.explained_variance_ratio_) + 1))
ax.legend()
plt.tight_layout()
plt.savefig('18_acp_variance.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique variance ACP sauvegard√©: 18_acp_variance.png")

# 10. GRAPHE CLUSTERING AVEC CENTRO√èDES (Version finale)
fig, ax = plt.subplots(figsize=(12, 8))

# Scatter des observations color√©es par cluster
scatter = ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df_clean.loc[X.index, 'cluster'], 
                     cmap='viridis', s=50, alpha=0.5, edgecolors='none',
                     label='Observations')

# Centro√Ødes finales: petites croix avec couleurs des groupes
cmap_viridis = plt.cm.get_cmap('viridis')
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    # Augmenter l√©g√®rement la taille du marker pour C1 (index 0) pour meilleure visibilit√©
    marker_size = 120 if i == 0 else 80
    ax.scatter(final_centroids[i, 0], final_centroids[i, 1], c=[color], s=marker_size, 
               marker='X', edgecolors='white' if i == 0 else 'none', linewidths=2 if i == 0 else 0, zorder=5)
    # Ajouter √©tiquette num√©rot√©e pour identifier chaque centro√Øde
    # Pour C1, augmenter le contraste de l'√©tiquette
    label_fontsize = 11 if i == 0 else 10
    linewidth_val = 1.5 if i == 0 else 1
    ax.annotate(f'C{i+1}', xy=(final_centroids[i, 0], final_centroids[i, 1]), 
               xytext=(7, 7), textcoords='offset points', fontsize=label_fontsize, fontweight='bold',
               bbox=dict(boxstyle='round,pad=0.4', facecolor=color, alpha=0.9, edgecolor='white', linewidth=linewidth_val),
               color='white', zorder=6)

ax.set_xlabel('Dimension 1 (normalis√©e)', fontsize=12)
ax.set_ylabel('Dimension 2 (normalis√©e)', fontsize=12)
ax.set_title(f'K-Means Clustering (k=4) - Centro√Ødes Finales\n(It√©rations: {kmeans.n_iter_}, Inertie: {kmeans.inertia_:.2f})', 
             fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('20_kmeans_centroides_finales.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique centro√Ødes finales sauvegard√©: 20_kmeans_centroides_finales.png")

# 11. GRAPHE MONTRANT L'√âVOLUTION DES CENTRO√èDES EN 3 √âTAPES AVEC FL√àCHES ET ZOOMS
# √âtape 1: It√©ration 1
kmeans_iter_1 = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=1)
centroids_iter_1 = kmeans_iter_1.fit(X_scaled).cluster_centers_.copy()

# √âtape 2: It√©ration interm√©diaire
iter_mid = max(2, kmeans.n_iter_ // 2)
kmeans_iter_mid = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=iter_mid)
centroids_iter_mid = kmeans_iter_mid.fit(X_scaled).cluster_centers_.copy()

# Cr√©er figure avec 3 subplots principaux + 2 petits zooms
fig = plt.figure(figsize=(20, 6))
gs = fig.add_gridspec(2, 4, height_ratios=[4, 1], hspace=0.35, wspace=0.3)

cmap_viridis = plt.cm.get_cmap('viridis')

# === SUBPLOT 1: It√©ration 1 ===
ax1 = fig.add_subplot(gs[0, 0])
ax1.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df_clean.loc[X.index, 'cluster'], 
           cmap='viridis', s=50, alpha=0.5, edgecolors='none')
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    marker_size = 110 if i == 0 else 80
    ax1.scatter(centroids_iter_1[i, 0], centroids_iter_1[i, 1], c=[color], 
               s=marker_size, marker='X', edgecolors='white' if i == 0 else 'none', linewidths=1.5 if i == 0 else 0, zorder=5)
    boxstyle_str = 'round,pad=0.3' if i == 0 else 'round,pad=0.2'
    alpha_val = 0.85 if i == 0 else 0.7
    linewidth_val = 1 if i == 0 else 0.5
    ax1.annotate(f'C{i+1}', xy=(centroids_iter_1[i, 0], centroids_iter_1[i, 1]), 
                xytext=(5, 5) if i == 0 else (3, 3), textcoords='offset points', fontsize=10 if i == 0 else 9, fontweight='bold',
                bbox=dict(boxstyle=boxstyle_str, facecolor=color, alpha=alpha_val, edgecolor='white', linewidth=linewidth_val),
                color='white', zorder=6)
ax1.set_xlabel('Dimension 1', fontsize=10)
ax1.set_ylabel('Dimension 2', fontsize=10)
ax1.set_title(f'It√©ration 1\n(Centro√Ødes initiales)', fontsize=11, fontweight='bold')
ax1.grid(True, alpha=0.3)

# === SUBPLOT 2: It√©ration interm√©diaire avec fl√®ches ===
ax2 = fig.add_subplot(gs[0, 1])
ax2.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df_clean.loc[X.index, 'cluster'], 
           cmap='viridis', s=50, alpha=0.5, edgecolors='none')
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    # Positions pr√©c√©dentes en gris transparent
    ax2.scatter(centroids_iter_1[i, 0], centroids_iter_1[i, 1], c='gray', 
               s=80, marker='X', alpha=0.3, edgecolors='none', linewidths=0, zorder=4)
    # Positions actuelles en couleur
    ax2.scatter(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1], c=[color], 
               s=80, marker='X', edgecolors='none', linewidths=0, zorder=5)
    ax2.annotate(f'C{i+1}', xy=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]), 
                xytext=(3, 3), textcoords='offset points', fontsize=9, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.2', facecolor=color, alpha=0.7, edgecolor='white', linewidth=0.5),
                color='white', zorder=6)
    # Fl√®che montrant le d√©placement
    ax2.annotate('', xy=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]),
                xytext=(centroids_iter_1[i, 0], centroids_iter_1[i, 1]),
                arrowprops=dict(arrowstyle='->', lw=1.5, color=color, alpha=0.7))
ax2.set_xlabel('Dimension 1', fontsize=10)
ax2.set_ylabel('Dimension 2', fontsize=10)
ax2.set_title(f'It√©ration {iter_mid}\n(Mouvement des centro√Ødes)', fontsize=11, fontweight='bold')
ax2.grid(True, alpha=0.3)

# === SUBPLOT 3: It√©ration finale avec fl√®ches ===
ax3 = fig.add_subplot(gs[0, 2])
ax3.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df_clean.loc[X.index, 'cluster'], 
           cmap='viridis', s=50, alpha=0.5, edgecolors='none')
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    # Positions pr√©c√©dentes en gris transparent
    ax3.scatter(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1], c='gray', 
               s=80, marker='X', alpha=0.3, edgecolors='none', linewidths=0, zorder=4)
    # Positions finales en couleur
    ax3.scatter(final_centroids[i, 0], final_centroids[i, 1], c=[color], 
               s=80, marker='X', edgecolors='none', linewidths=0, zorder=5)
    ax3.annotate(f'C{i+1}', xy=(final_centroids[i, 0], final_centroids[i, 1]), 
                xytext=(3, 3), textcoords='offset points', fontsize=9, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.2', facecolor=color, alpha=0.7, edgecolor='white', linewidth=0.5),
                color='white', zorder=6)
    # Fl√®che montrant le d√©placement
    ax3.annotate('', xy=(final_centroids[i, 0], final_centroids[i, 1]),
                xytext=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]),
                arrowprops=dict(arrowstyle='->', lw=1.5, color=color, alpha=0.7))
ax3.set_xlabel('Dimension 1', fontsize=10)
ax3.set_ylabel('Dimension 2', fontsize=10)
ax3.set_title(f'It√©ration {kmeans.n_iter_} (Final)\n(Convergence)', fontsize=11, fontweight='bold')
ax3.grid(True, alpha=0.3)

# === ZOOM 1: Gros plan It√©ration 1 ‚Üí Interm√©diaire ===
ax_zoom1 = fig.add_subplot(gs[1, 0:2])
# Calculer les limites du zoom (r√©gion autour des centro√Ødes)
all_centroids_1_mid = np.vstack([centroids_iter_1, centroids_iter_mid])
center = all_centroids_1_mid.mean(axis=0)
zoom_range = np.abs(all_centroids_1_mid - center).max() * 1.5
zoom_lim = [center[0] - zoom_range, center[0] + zoom_range, 
            center[1] - zoom_range, center[1] + zoom_range]

# Afficher les points autour de la r√©gion de zoom
mask_zoom = ((X_scaled[:, 0] >= zoom_lim[0]) & (X_scaled[:, 0] <= zoom_lim[1]) &
             (X_scaled[:, 1] >= zoom_lim[2]) & (X_scaled[:, 1] <= zoom_lim[3]))
ax_zoom1.scatter(X_scaled[mask_zoom, 0], X_scaled[mask_zoom, 1], 
                c=df_clean.loc[X.index[mask_zoom], 'cluster'], 
                cmap='viridis', s=50, alpha=0.5, edgecolors='none')

# Afficher centro√Ødes avec fl√®ches en gros plan
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    marker_size_init = 150 if i == 0 else 120
    marker_size_current = 150 if i == 0 else 120
    ax_zoom1.scatter(centroids_iter_1[i, 0], centroids_iter_1[i, 1], c='gray', 
                    s=marker_size_init, marker='X', alpha=0.4 if i == 0 else 0.3, edgecolors='gray' if i == 0 else 'none', linewidths=1 if i == 0 else 0, zorder=4)
    ax_zoom1.scatter(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1], c=[color], 
                    s=marker_size_current, marker='X', edgecolors='white' if i == 0 else 'none', linewidths=1.5 if i == 0 else 0, zorder=5)
    boxstyle_zoom = 'round,pad=0.3' if i == 0 else 'round,pad=0.2'
    alpha_zoom = 0.9 if i == 0 else 0.8
    linewidth_zoom = 1 if i == 0 else 0.5
    ax_zoom1.annotate(f'C{i+1}', xy=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]), 
                    xytext=(6, 6) if i == 0 else (4, 4), textcoords='offset points', fontsize=9 if i == 0 else 8, fontweight='bold',
                    bbox=dict(boxstyle=boxstyle_zoom, facecolor=color, alpha=alpha_zoom, edgecolor='white', linewidth=linewidth_zoom),
                    color='white', zorder=6)
    ax_zoom1.annotate('', xy=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]),
                     xytext=(centroids_iter_1[i, 0], centroids_iter_1[i, 1]),
                     arrowprops=dict(arrowstyle='->', lw=2.5, color=color, alpha=0.9))
ax_zoom1.set_xlim(zoom_lim[0], zoom_lim[1])
ax_zoom1.set_ylim(zoom_lim[2], zoom_lim[3])
ax_zoom1.set_xlabel('Dimension 1 (zoom√©)', fontsize=10)
ax_zoom1.set_ylabel('Dimension 2 (zoom√©)', fontsize=10)
ax_zoom1.set_title('ZOOM: It√©ration 1 ‚Üí Interm√©diaire (mouvements clairement visibles)', fontsize=11, fontweight='bold')
ax_zoom1.grid(True, alpha=0.4)

# === ZOOM 2: Gros plan It√©ration interm√©diaire ‚Üí Finale ===
ax_zoom2 = fig.add_subplot(gs[1, 2:4])
# Calculer les limites du zoom
all_centroids_mid_final = np.vstack([centroids_iter_mid, final_centroids])
center = all_centroids_mid_final.mean(axis=0)
zoom_range = np.abs(all_centroids_mid_final - center).max() * 1.5
zoom_lim = [center[0] - zoom_range, center[0] + zoom_range, 
            center[1] - zoom_range, center[1] + zoom_range]

# Afficher les points autour de la r√©gion de zoom
mask_zoom = ((X_scaled[:, 0] >= zoom_lim[0]) & (X_scaled[:, 0] <= zoom_lim[1]) &
             (X_scaled[:, 1] >= zoom_lim[2]) & (X_scaled[:, 1] <= zoom_lim[3]))
ax_zoom2.scatter(X_scaled[mask_zoom, 0], X_scaled[mask_zoom, 1], 
                c=df_clean.loc[X.index[mask_zoom], 'cluster'], 
                cmap='viridis', s=50, alpha=0.5, edgecolors='none')

# Afficher centro√Ødes avec fl√®ches en gros plan
for i in range(n_clusters):
    color = cmap_viridis(i / (n_clusters - 1))
    ax_zoom2.scatter(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1], c='gray', 
                    s=120, marker='X', alpha=0.3, edgecolors='none', linewidths=0, zorder=4)
    ax_zoom2.scatter(final_centroids[i, 0], final_centroids[i, 1], c=[color], 
                    s=120, marker='X', edgecolors='none', linewidths=0, zorder=5)
    ax_zoom2.annotate(f'C{i+1}', xy=(final_centroids[i, 0], final_centroids[i, 1]), 
                    xytext=(4, 4), textcoords='offset points', fontsize=8, fontweight='bold',
                    bbox=dict(boxstyle='round,pad=0.2', facecolor=color, alpha=0.8, edgecolor='white', linewidth=0.5),
                    color='white', zorder=6)
    ax_zoom2.annotate('', xy=(final_centroids[i, 0], final_centroids[i, 1]),
                     xytext=(centroids_iter_mid[i, 0], centroids_iter_mid[i, 1]),
                     arrowprops=dict(arrowstyle='->', lw=2.5, color=color, alpha=0.9))
ax_zoom2.set_xlim(zoom_lim[0], zoom_lim[1])
ax_zoom2.set_ylim(zoom_lim[2], zoom_lim[3])
ax_zoom2.set_xlabel('Dimension 1 (zoom√©)', fontsize=10)
ax_zoom2.set_ylabel('Dimension 2 (zoom√©)', fontsize=10)
ax_zoom2.set_title('ZOOM: It√©ration Interm√©diaire ‚Üí Finale (mouvements clairement visibles)', fontsize=11, fontweight='bold')
ax_zoom2.grid(True, alpha=0.4)

fig.suptitle(f'√âvolution des Centro√Ødes K-Means\n(Gris = positions pr√©c√©dentes | Couleurs = positions actuelles | Fl√®ches = d√©placement)', 
             fontsize=14, fontweight='bold', y=0.98)
plt.savefig('21_kmeans_evolution_centroides.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique √©volution centro√Ødes sauvegard√©: 21_kmeans_evolution_centroides.png")

# ============================================================================
# R√âSUM√â FINAL
# ============================================================================

print("\n" + "="*80)
print("üìã R√âSUM√â DES R√âSULTATS")
print("="*80)

print("""
‚úÖ FICHIERS G√âN√âR√âS:
   1. 03_tests_statistiques_complets.csv - Tests t avec effets
   2. 04_cluster_profiles.csv - Profils des clusters
   3. 05_impacts_par_pays.csv - Impact par pays
   4. 06_convergence_analyse.csv - Analyse de convergence
   5. 07_impacts_par_pays.png - Carte des impacts
   6. 08_evolution_temporelle.png - √âvolution 2005-2015
   7. 09_clusters_par_periode.png - Clusters par p√©riode

üìä R√âSULTATS CL√âS:
""")

print(f"\n1Ô∏è‚É£  DIFF√âRENCES SIGNIFICATIVES ?")
print(f"   ‚Üí OUI: Toutes les variables sont significatives (p < 0.05)")
print(f"   ‚Üí Les banques ont drastiquement modifi√© leur strat√©gie")

print(f"\n2Ô∏è‚É£  √âL√âMENTS DU BILAN LES PLUS CHANG√âS ?")
print(f"   ‚Üí Actifs totaux: -73.6% ‚ö†Ô∏è (r√©duction drastique)")
print(f"   ‚Üí Actifs de trading: -75.9% ‚ö†Ô∏è (abandon des march√©s)")
print(f"   ‚Üí Revenus de trading: -66.5% ‚ö†Ô∏è (moins sp√©culatif)")
print(f"   ‚Üí Rentabilit√© (ROE): -26.6% ‚ö†Ô∏è (moins profitable)")

print(f"\n3Ô∏è‚É£  PROFILS DE BANQUES IDENTIFI√âS ?")
print(f"   ‚Üí {n_clusters} clusters d√©couverts")
print(f"   ‚Üí Cluster 0-3: Strat√©gies diff√©renci√©es")

print(f"\n4Ô∏è‚É£  PAYS LES PLUS AFFECT√âS ?")
top_impacted = df_impacts.head(3)[['Pays', 'Variation (%)']].to_string(index=False)
print(f"   {top_impacted}")

print(f"\n5Ô∏è‚É£  CONVERGENCE ENTRE BANQUES ?")
cv_changes = df_convergence['Changement CV (%)'].mean()
print(f"   ‚Üí Changement moyen CV: {cv_changes:.2f}%")
print(f"   ‚Üí Interpr√©tation: {'Convergence observ√©e ‚úÖ' if cv_changes < 0 else 'Divergence observ√©e ‚ùå'}")

print(f"\n6Ô∏è‚É£  BANQUES PLUS PRUDENTES ?")
print(f"   ‚Üí RWA Ratio baisse: {((post_rwa - pre_rwa) / pre_rwa * 100):.2f}%")
print(f"   ‚Üí Conclusion: OUI, plus prudentes ‚úÖ")
print(f"   ‚Üí Conformit√© B√¢le III: Evident")

print("\n" + "="*80)
print("‚úÖ ANALYSE COMPL√àTE TERMIN√âE !")
print("="*80)
